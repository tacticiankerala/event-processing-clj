# event-processing

An Onyx application that does distributed things. This uses RabbitMq and Mqtt as input source and writes the events to a Postgresql database. 

## Usage

1. Start RabbitMQ, Postgresql, and Dashboard docker containers with docker-compose

2. Goto RabbitMq dashboard (`http://localhost:15672`, username: `guest` password `guest`) and import the RabbitMq configuration found in this repo(`scripts/onyx_rabbitmq_config.json`)

3. Setup Postgresql db by running `psql -h $(echo $DOCKER_HOST|cut -d ':' -f 2|sed "s/\/\///g") -p 5432 -U postgres < script/postgres/migrations.sql`

### Development

1. Start peers and submit job from lein repl

   - Start lein repl in dev mode `lein with-profile +dev repl`
   - Start peers

     ```
     (use 'event-processing.jobs.sample-submit-job)
     (require 'event-processing.tasks.core-async)
     (require 'onyx.api)
     (use 'aero.core)
     (def id "1")
     (def n-peers 6)
     (def config (read-config (clojure.java.io/resource "config.edn") {:profile :dev}))
     (def env-config (assoc (:env-config config) :onyx/id id))
     (def peer-config (assoc (:peer-config config) :onyx/id id))
     (def peer-group (onyx.api/start-peer-group peer-config))
     (def env (onyx.api/start-env (:env-config config)))
     (def peers (onyx.api/start-peers n-peers peer-group))
     ```
     
   - Submit the job
   
    ``` (onyx.api/submit-job peer-config (build-job :dev)) ```
    
2. In order to stop the peers, run the following

   ```
   (onyx.api/shutdown-peers peers)
   (onyx.api/shutdown-env env)
   (onyx.api/shutdown-peer-group peer-group)
   ```
   
3. How to test the setup?

   - use [Mosquitto clients](http://mosquitto.org/download/) to test RabbitMq and Mqtt.
     eg: `mosquitto_pub -t device/heartbeat -m "{\"deviceId\" : \"1232342323232\", \"createdAt\" : \"12335533\"}""\"}"`
   - use Onyx dashboard(`http://localhost:3000`)
   - use RabbitMq management plugin(`http://localhost:15672`), username: `guest` password `guest`
   - tail `onyx.log` in the app root directory

4. Reloading the code

   - `(clojure.tools.namespace.repl/refresh)` can be used with this setup to refresh your project.
   
######TODO:

        1. Use component to automate starting and stopping peers.
        2. Configure RabbitMq when starting docker container starts


### Production
Running onyx in production just requires building an uberjar and running
the `event-processing.launcher.launch_prod_peers` function with an `onyx_id` and a `npeers`
argument.

`onyx_id` will essentially namespace this particular peer to a cluster.
This allows you to run multiple groups of onyx environments with the same
zookeeper ensemble.

`npeers` will create multiple peers (units to execute tasks in a workflow) on
the same JVM. It is recommended you have 1 peer per core.

You are also going to want to verify that the peer-config in `resources/config.edn`
is correct. Specifically that `:zookeeper/address` contains a ZK server in your
ensemble, and that your `:onyx.messaging/bind-addr` is an address reachable
by any other peer in the cluster.

For our case right now, `:zookeeper/address` is set to use "zk:2181", and since
we only have one physical node running several peers, localhost is reachable by
all the peers in the cluster.

Submitting a job to a production cluster is exactly the same as in the
development example. You generate your job (this time with `:prod` instead of
`:dev`), and call `submit-job`. This time your peer config will come from
'resources/config.edn' instead of the anaphoric macro though.

### Prerequisites

1. [Docker ToolBox](https://www.docker.com/products/docker-toolbox/)
2. On Windows or Mac OS X, setup a local VM with VirtualBox, see [get started](https://docs.docker.com/machine/get-started/)
3. Java 8

### Execution

##### Make sure to set the Docker Machine env

If you are using docker-machine, make sure to setup your environment:
`eval "$(docker-machine env default)"`

where default is the name of your docker-machine box.

##### Building the Cluster

First we will build the example app. Out of the box the lein template includes all that you would need to stream from meetup.com->Kafka->Onyx->PostgreSQL. Run the build script (with Java 8).

`./script/build.sh`
    
**Once** That finishes, you can run `docker-compose up` to download, configure and launch the rest of the containers. Once that completes (it will take some time), you will have a fully configured Onyx cluster. This cluster (of one physical node, and default 6 peers) is fully able to receive jobs. Let's try to submit one. 

                                
Now with everything configured, we can finally submit to the cluster.

##### Submitting the Job

**Submitting** a job is done using the `onyx.api/submit-job` function. It takes a [peer config](http://www.onyxplatform.org/cheat-sheet.html#/peer-config) and a job description map (such as the one generated by `event-processing.jobs.sample-submit-job/build-job`), and submits the job to the specified Onyx cluster. 

Note, you will need to start your repl with the ZOOKEEPER environment variable set to your docker host, or edit `resources/config.edn` to configure the zookeeper string.

You can also submit the job via the command-line as follows:
`ZOOKEEPER=$(echo $DOCKER_HOST|cut -d ':' -f 2|sed "s/\/\///g") lein run -m event-processing.jobs.sample-submit-job`

Publish an event as follows:
`mosquitto_pub -t device/heartbeat -m "{\"deviceId\" : \"1232342323232\", \"createdAt\" : \"12335533\"}""\"}"`

### Results
You should now see results streaming into PostgreSQL when you select from the table in PostgreSQL:

```

psql> \c onemdm;
psql> select * from heartbeats;
id  |   deviceid    |        createdat
----+---------------+-------------------------
  1 | 1232342323232 | 1970-01-01 03:25:35.533
  
```

### Tips
1. Whenever you make a code change, you need to re-run the `script/build.sh` to remake your docker container with the new jar.
2. Use `docker-compose rm` to delete the PostgreSQL/Rabbitmq datastores and start fresh

## License

Copyright Â© 2016

Distributed under the Eclipse Public License either version 1.0 or (at
your option) any later version.
